{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a31dd46",
   "metadata": {},
   "source": [
    "## Prepare data ##\n",
    "Cell 1: Configuration\n",
    "AWESOME_CV_BASE, \n",
    "OUTPUT_ORGANIZED \n",
    "\n",
    "Cell 2: Run organization\n",
    "main()\n",
    "\n",
    "Cell 3: Explore specific category\n",
    "from pathlib import Path\n",
    "\n",
    "List all summary files\n",
    "summary_dir = Path(OUTPUT_ORGANIZED) / \"summary\"\n",
    "for f in sorted(summary_dir.glob(\"*.tex\"))[:10]:\n",
    "    print(f.name)\n",
    "\n",
    "Cell 4: Search for specific content\n",
    "analyzer = CVAnalysisTools(OUTPUT_ORGANIZED)\n",
    "\n",
    "Find all cancer-related experience files\n",
    "cancer_files = analyzer.find_similar_files(\"cancer\", category=\"experience\")\n",
    "\n",
    "Cell 5: Compare two similar files\n",
    "if len(cancer_files) >= 2:\n",
    "    analyzer.compare_files(cancer_files[0], cancer_files[1])\n",
    "```\n",
    "\n",
    "ğŸ“‚ Output Structure\n",
    "```\n",
    "organized_files/\n",
    "â”œâ”€â”€ summary/\n",
    "â”‚   â”œâ”€â”€ Bioinformatics_2025_03__summary_bioinformatics_busi_2025_03.tex\n",
    "â”‚   â”œâ”€â”€ DS_2025__summary_DS_project_busi_2025_03.tex\n",
    "â”‚   â””â”€â”€ ... (many more)\n",
    "â”œâ”€â”€ experience/\n",
    "â”‚   â”œâ”€â”€ Bioinformatics_2025_03__experience_bioinformatics_2025_03.tex\n",
    "â”‚   â”œâ”€â”€ DS_Healthcare_2025_05__experience_DS_2025_05.tex\n",
    "â”‚   â””â”€â”€ ...\n",
    "â”œâ”€â”€ key_skills/\n",
    "â”‚   â”œâ”€â”€ Bioinformatics_2025_05__key_skills_2025_05.tex\n",
    "â”‚   â”œâ”€â”€ IT_HPC_2025_04__key_skills_2025_04_IT.tex\n",
    "â”‚   â””â”€â”€ ...\n",
    "â”œâ”€â”€ education/\n",
    "â”œâ”€â”€ additional_info/\n",
    "â”œâ”€â”€ file_mappings.json\n",
    "â”œâ”€â”€ ORGANIZATION_REPORT.md\n",
    "â””â”€â”€ statistics.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f2893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:62: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:62: SyntaxWarning: invalid escape sequence '\\i'\n",
      "/var/folders/8l/dg2tx1j914nbpcy558d8wzym0000gn/T/ipykernel_63680/117704964.py:62: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  Extract all \\input{...} file references from a resume file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "ğŸ“ CV FILES ORGANIZER\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‚ Source: /Users/kbillis/bin/Awesome-CV/examples\n",
      "ğŸ“‚ Output: /Users/kbillis/bin/Awesome-CV/organized_files\n",
      "\n",
      "======================================================================\n",
      "ğŸ“ CV FILES ORGANIZER\n",
      "======================================================================\n",
      "ğŸ” Scanning /Users/kbillis/bin/Awesome-CV/examples for resume files...\n",
      "âœ… Found 83 resume files\n",
      "\n",
      "ğŸ“‹ Extracting input files from resumes...\n",
      "   Processing: client_Platform_Nvidia_Med_2025_10/resume_konstantinos_billis.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Bioinformatics_2025_09_biomarkers/resume_konstantinos_billis_25_09_Biomarkers.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Software_dev_2025_09/resume_konstantinos_billis_25_09_softw.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: client_Platform_Med_2025_10/resume_konstantinos_billis.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Data_Architect_2025_06/resume_konstantinos_billis.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: DS_engineer_2024_03/resume_konstantinos_billis_25_03_DS.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Architect_2025_09/resume_konstantinos_billis.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Engineer_2025_06/resume_konstantinos_billis_25_05_DA.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Engineer_2025_06/resume_konstantinos_billis_25_05_Bioinformatics.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Engineer_2025_06/resume_konstantinos_billis_25_05_DA_R.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Architect_2025_07/resume_konstantinos_billis.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: DS_Healthcare_2025_09_patient_data/resume_konstantinos_billis_25_04_DS.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Bioinformatics_2024_09/resume_konstantinos_billis_24_09_Bioinformatics.tex\n",
      "      âœ“ Found 3 input files\n",
      "   Processing: Bioinformatics_2024_09/resume_konstantinos_billis_24_09_Bioinformatics_business.tex\n",
      "      âœ“ Found 3 input files\n",
      "   Processing: Bioinformatics_2024_07/resume_konstantinos_billis_24_07_Bioinformatics.tex\n",
      "      âœ“ Found 2 input files\n",
      "   Processing: Bioinformatics_2024_07/resume_konstantinos_billis_24_07_Bioinformatics_AI.tex\n",
      "      âœ“ Found 2 input files\n",
      "   Processing: DS_Healthcare_2025_05/resume_konstantinos_billis_25_04_DS.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: DS_2025/resume_konstantinos_billis_25_03_DS.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Lead_2024_10/resume_konstantinos_billis_24_10_lead.tex\n",
      "      âœ“ Found 3 input files\n",
      "   Processing: DS_Healthcare_2025_04/resume_konstantinos_billis_25_04_DS.tex\n",
      "      âœ“ Found 3 input files\n",
      "   Processing: business_2024_12/resume_konstantinos_billis_24_12_Business_HC.tex\n",
      "   Processing: Bioinformatics_2025_06/resume_konstantinos_billis_25_06_Bioinformatics.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Bioinformatics_2025_07_ETH_omics/resume_konstantinos_billis_25_06_Bioinformatics.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Bioinformatics_2025_08/resume_konstantinos_billis_25_08_Bioinformatics.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: IT_HPC_2025_04/resume_konstantinos_billis_25_04_IT.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: business_Data_Med_2025_09/resume_konstantinos_billis_25_08.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: LEAD_data_engineer_JJ_2025_10/resume_konstantinos_billis.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Bioinformatics_2025_09/resume_konstantinos_billis_25_08_Bioinformatics.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Plants_2025_09/resume_konstantinos_billis_25_09_Plants.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Plants_2025_07/resume_konstantinos_billis_25_03_Plants.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Bioinformatics_2025_10_RNA/resume_konstantinos_billis_25_08_Bioinformatics.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: DS_Healthcare_2025_05_epi/resume_konstantinos_billis_25_04_DS.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: DS_LIMS_2025_06/resume_konstantinos_billis_LIMSs.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: IT_DATA_LEAD_2025_08/resume_konstantinos_billis_25_04_IT.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Software_dev_2025_05/resume_konstantinos_billis_25_05_DA.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Software_dev_2025_05/resume_konstantinos_billis_25_05_Bioinformatics.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: IT_HPC_Pfizer_2025_04/resume_konstantinos_billis_25_04_IT.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Bioinformatics_2025_10_SIB/resume_konstantinos_billis_25_08_Bioinformatics.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Bioinformatics_2025_07_biot/resume_konstantinos_billis_25_06_Bioinformatics.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Architect_2025_05/resume_konstantinos_billis_25_05_DA.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Architect_2025_05/resume_konstantinos_billis_25_05_Bioinformatics.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Architect_2025_05/resume_konstantinos_billis_25_05_DA_R.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Bioinformatics_2024_10/resume_konstantinos_billis_24_10_Bioinformatics_business.tex\n",
      "      âœ“ Found 3 input files\n",
      "   Processing: Data_Analytics_Med_2025_08/resume_konstantinos_billis_25_08.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Bioinformatics_Data_product_2025_04/resume_konstantinos_billis_25_04_DS.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Bioinformatics_manager_2024_12/resume_konstantinos_billis_24_10_Bioinformatics_business.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Bioinformatics_manager_2024_12/resume_konstantinos_billis_24_12_Bioinformatics_business.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Bioinformatics_2025_09_cancer/resume_konstantinos_billis_25_09_Biomarkers.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Bioinformatics_2025_04_ncRNA/resume_konstantinos_billis_25_03_Bioinformatics.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Science_Novartis_2025_08/resume_konstantinos_billis_25_08_Bioinformatics.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: DS_clinical_2024_09/resume_konstantinos_billis_24_09_DS_clinical.tex\n",
      "      âœ“ Found 3 input files\n",
      "   Processing: Bioinformatics_2025_05/resume_konstantinos_billis_25_05_Bioinformatics.tex\n",
      "      âœ“ Found 2 input files\n",
      "   Processing: business_Data_Prec_Med_2025_10/resume_konstantinos_billis.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Data_Product_2025_06/resume_konstantinos_billis.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Plants_2025_03/resume_konstantinos_billis_25_03_Plants.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Science_Takeda_2025_06/resume_konstantinos_billis_25_05_DA.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Data_Science_Takeda_2025_06/resume_konstantinos_billis_25_05_Bioinformatics.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Bioinformatics_2025_07_biomarkers/resume_konstantinos_billis_25_08_Bioinformatics.tex\n",
      "      âœ“ Found 5 input files\n",
      "   Processing: Bioinformatics_2025_03/resume_konstantinos_billis_25_03_Bioinformatics.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: Senior_Bioinformatics_Scientist_Roche_2025_11/resume_konstantinos_billis_Senior_Bioinformatics_Scientist.tex\n",
      "      âœ“ Found 2 input files\n",
      "   Processing: DS_Healthcare_product_2025_04/resume_konstantinos_billis_25_04_DS.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: IT_Manager_2025_04/resume_konstantinos_billis_25_04_IT_business.tex\n",
      "      âœ“ Found 4 input files\n",
      "   Processing: business/resume_konstantinos_billis_24_09_Business.tex\n",
      "   Processing: business/resume_konstantinos_billis_24_04_business024_02_.tex\n",
      "   Processing: business/resume_konstantinos_billis_24_09_Business_HC.tex\n",
      "   Processing: business/resume_konstantinos_billis_24_09_lead.tex\n",
      "      âœ“ Found 1 input files\n",
      "   Processing: Science/resume_konstantinos_billis_24_05_Bio_business.tex\n",
      "   Processing: Science/resume_konstantinos_billis_24_04_science.tex\n",
      "   Processing: Science/resume_konstantinos_billis_24_05_Bioinformatics.tex\n",
      "   Processing: Science/resume_konstantinos_billis_24_05_Data_science.tex\n",
      "   Processing: Training_position/resume_konstantinos_billis_25_03_Train.tex\n",
      "      âœ“ Found 1 input files\n",
      "   Processing: LEAD_positions/resume_konstantinos_billis_24_09_lead.tex\n",
      "      âœ“ Found 1 input files\n",
      "   Processing: resume_KB/resume_konstantinos_billis_2024_06_Business.tex\n",
      "   Processing: resume_KB/resume_konstantinos_billis_2023_10_RoEn.tex\n",
      "   Processing: resume_KB/resume_konstantinos_billis_2023_11_RoEn.tex\n",
      "   Processing: resume_KB/resume_konstantinos_billis.tex\n",
      "   Processing: resume_KB/resume_konstantinos_billis_2023_10.tex\n",
      "   Processing: resume_KB/resume_konstantinos_billis_2023_07.tex\n",
      "   Processing: resume_KB/resume_konstantinos_billis_2023_11_Finance.tex\n",
      "   Processing: resume_KB/resume_konstantinos_billis_Mar_2023.tex\n",
      "   Processing: resume_KB/resume_konstantinos_billis_2024_02_science.tex\n",
      "   Processing: resume_KB/resume_konstantinos_billis_2023_10_General.tex\n",
      "   Processing: resume_KB/resume_konstantinos_billis_2023_10_Business.tex\n",
      "\n",
      "ğŸ“‚ Creating organized directory structure...\n",
      "\n",
      "   ğŸ“ SUMMARY: 46 unique files\n",
      "      âœ… Copied 46/46 files\n",
      "\n",
      "   ğŸ“ KEY_SKILLS: 58 unique files\n",
      "      âœ… Copied 58/58 files\n",
      "\n",
      "   ğŸ“ EXPERIENCE: 48 unique files\n",
      "      âœ… Copied 48/48 files\n",
      "\n",
      "   ğŸ“ EDUCATION: 17 unique files\n",
      "      âœ… Copied 17/17 files\n",
      "\n",
      "   ğŸ“ ADDITIONAL_INFO: 13 unique files\n",
      "      âœ… Copied 13/13 files\n",
      "\n",
      "ğŸ“„ Creating mapping file...\n",
      "      âœ… Saved: file_mappings.json\n",
      "      âœ… Saved: ORGANIZATION_REPORT.md\n",
      "\n",
      "âœ… Organization complete!\n",
      "   Output directory: /Users/kbillis/bin/Awesome-CV/organized_files\n",
      "   Total categories: 5\n",
      "   Total unique files: 182\n",
      "\n",
      "ğŸ“‹ Creating category indexes...\n",
      "   âœ… Created index for: experience\n",
      "   âœ… Created index for: education\n",
      "   âœ… Created index for: additional_info\n",
      "   âœ… Created index for: key_skills\n",
      "   âœ… Created index for: summary\n",
      "\n",
      "======================================================================\n",
      "ğŸ“Š RUNNING ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Generating statistics...\n",
      "\n",
      "======================================================================\n",
      "ğŸ“ˆ STATISTICS SUMMARY\n",
      "======================================================================\n",
      "                 files  total_size     avg_size  source_dirs\n",
      "key_skills        57.0    134033.0  2351.456140         43.0\n",
      "experience        48.0    246899.0  5143.729167         45.0\n",
      "summary           46.0     54646.0  1187.956522         44.0\n",
      "education         17.0     43168.0  2539.294118         17.0\n",
      "additional_info   13.0     23655.0  1819.615385         13.0\n",
      "\n",
      "âœ… Saved statistics to: /Users/kbillis/bin/Awesome-CV/organized_files/statistics.csv\n",
      "\n",
      "======================================================================\n",
      "ğŸ” EXAMPLE SEARCHES\n",
      "======================================================================\n",
      "\n",
      "ğŸ” Searching for: 'bioinformatics'\n",
      "âœ… Found 33 matching files\n",
      "\n",
      "   Top bioinformatics summaries:\n",
      "      â€¢ Bioinformatics_2025_09_cancer__summary_bioinformatics.tex\n",
      "      â€¢ business_Data_Med_2025_09__summary_bioinformatics.tex\n",
      "      â€¢ Bioinformatics_2025_03__summary_bioinformatics_busi_2025_03.tex\n",
      "\n",
      "ğŸ” Searching for: 'python'\n",
      "âœ… Found 44 matching files\n",
      "\n",
      "   Files mentioning Python:\n",
      "      â€¢ LEAD_data_engineer_JJ_2025_10__key_skills.tex\n",
      "      â€¢ IT_Manager_2025_04__key_skills_2025_04_DS_compressed.tex\n",
      "      â€¢ Bioinformatics_Data_product_2025_04__key_skills_2025_04_bio_business.tex\n",
      "\n",
      "======================================================================\n",
      "âœ… ORGANIZATION COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "ğŸ“ Check output directory: /Users/kbillis/bin/Awesome-CV/organized_files\n",
      "ğŸ“„ Read: ORGANIZATION_REPORT.md\n",
      "ğŸ“‹ Browse categories:\n",
      "      â€¢ experience/  (48 files)\n",
      "      â€¢ education/  (17 files)\n",
      "      â€¢ additional_info/  (13 files)\n",
      "      â€¢ key_skills/  (57 files)\n",
      "      â€¢ summary/  (46 files)\n"
     ]
    }
   ],
   "source": [
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ğŸ“ CV FILES ORGANIZER\n",
    "# Extract and organize CV component files from Awesome-CV directories\n",
    "# Groups files by type (summary, skills, experience, etc.)\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Set, Tuple\n",
    "import pandas as pd\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CONFIGURATION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# Update these paths\n",
    "AWESOME_CV_BASE = \"/Users/kbillis/bin/Awesome-CV/examples\"\n",
    "OUTPUT_ORGANIZED = \"/Users/kbillis/bin/Awesome-CV/organized_files\"\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# CV FILES EXTRACTOR\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class CVFilesOrganizer:\n",
    "    \"\"\"Extract and organize CV component files.\"\"\"\n",
    "    \n",
    "    def __init__(self, base_path: str, output_path: str):\n",
    "        self.base_path = Path(base_path)\n",
    "        self.output_path = Path(output_path)\n",
    "        self.file_mapping = defaultdict(list)\n",
    "        \n",
    "        # File type categories\n",
    "        self.file_categories = {\n",
    "            'summary': ['summary', 'objective'],\n",
    "            'experience': ['experience', 'work', 'employment'],\n",
    "            'key_skills': ['key_skills', 'skills', 'competencies'],\n",
    "            'education': ['education', 'academic'],\n",
    "            'additional_info': ['additional_info', 'additional', 'extra'],\n",
    "            'honors': ['honors', 'awards', 'achievements'],\n",
    "            'publications': ['publications', 'papers', 'writing'],\n",
    "            'projects': ['projects', 'portfolio']\n",
    "        }\n",
    "    \n",
    "    def find_all_resume_files(self) -> List[Path]:\n",
    "        \"\"\"Find all resume*.tex files.\"\"\"\n",
    "        resume_files = []\n",
    "        \n",
    "        print(f\"ğŸ” Scanning {self.base_path} for resume files...\")\n",
    "        \n",
    "        for resume_file in self.base_path.rglob(\"resume*.tex\"):\n",
    "            if resume_file.is_file():\n",
    "                resume_files.append(resume_file)\n",
    "        \n",
    "        print(f\"âœ… Found {len(resume_files)} resume files\")\n",
    "        return resume_files\n",
    "    \n",
    "    def extract_input_files(self, resume_file: Path) -> List[Tuple[str, Path]]:\n",
    "        \"\"\"\n",
    "        Extract all \\input{...} file references from a resume file.\n",
    "        Returns list of (category, filepath) tuples.\n",
    "        Only includes non-commented lines.\n",
    "        \"\"\"\n",
    "        input_files = []\n",
    "        \n",
    "        try:\n",
    "            with open(resume_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                content = f.read()\n",
    "            \n",
    "            # Find all \\input{...} commands that are NOT commented\n",
    "            lines = content.split('\\n')\n",
    "            \n",
    "            for line in lines:\n",
    "                # Skip commented lines\n",
    "                if line.strip().startswith('%'):\n",
    "                    continue\n",
    "                \n",
    "                # Find \\input{filepath} pattern\n",
    "                match = re.search(r'\\\\input\\{(.+?)\\}', line)\n",
    "                if match:\n",
    "                    filepath_str = match.group(1)\n",
    "                    \n",
    "                    # Handle both absolute and relative paths\n",
    "                    if filepath_str.startswith('/'):\n",
    "                        filepath = Path(filepath_str)\n",
    "                    else:\n",
    "                        filepath = resume_file.parent / filepath_str\n",
    "                    \n",
    "                    # Only include if file exists\n",
    "                    if filepath.exists() and filepath.is_file():\n",
    "                        # Determine category\n",
    "                        category = self._categorize_file(filepath.name)\n",
    "                        input_files.append((category, filepath))\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"   âš ï¸  Error reading {resume_file}: {e}\")\n",
    "        \n",
    "        return input_files\n",
    "    \n",
    "    def _categorize_file(self, filename: str) -> str:\n",
    "        \"\"\"Categorize a file based on its name.\"\"\"\n",
    "        filename_lower = filename.lower()\n",
    "        \n",
    "        for category, keywords in self.file_categories.items():\n",
    "            for keyword in keywords:\n",
    "                if keyword in filename_lower:\n",
    "                    return category\n",
    "        \n",
    "        return 'other'\n",
    "    \n",
    "    def organize_files(self):\n",
    "        \"\"\"Main function to organize all CV files.\"\"\"\n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ğŸ“ CV FILES ORGANIZER\")\n",
    "        print(\"=\"*70)\n",
    "        \n",
    "        # Find all resume files\n",
    "        resume_files = self.find_all_resume_files()\n",
    "        \n",
    "        if not resume_files:\n",
    "            print(\"âŒ No resume files found!\")\n",
    "            return\n",
    "        \n",
    "        # Extract input files from each resume\n",
    "        print(f\"\\nğŸ“‹ Extracting input files from resumes...\")\n",
    "        \n",
    "        all_input_files = defaultdict(set)\n",
    "        resume_mappings = []\n",
    "        \n",
    "        for resume_file in resume_files:\n",
    "            print(f\"   Processing: {resume_file.parent.name}/{resume_file.name}\")\n",
    "            \n",
    "            input_files = self.extract_input_files(resume_file)\n",
    "            \n",
    "            mapping_entry = {\n",
    "                'resume': str(resume_file),\n",
    "                'directory': resume_file.parent.name,\n",
    "                'files': []\n",
    "            }\n",
    "            \n",
    "            for category, filepath in input_files:\n",
    "                all_input_files[category].add(filepath)\n",
    "                mapping_entry['files'].append({\n",
    "                    'category': category,\n",
    "                    'path': str(filepath),\n",
    "                    'name': filepath.name\n",
    "                })\n",
    "            \n",
    "            resume_mappings.append(mapping_entry)\n",
    "            \n",
    "            if input_files:\n",
    "                print(f\"      âœ“ Found {len(input_files)} input files\")\n",
    "        \n",
    "        # Create organized directory structure\n",
    "        print(f\"\\nğŸ“‚ Creating organized directory structure...\")\n",
    "        self.output_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        stats = {}\n",
    "        \n",
    "        for category, filepaths in all_input_files.items():\n",
    "            if not filepaths:\n",
    "                continue\n",
    "            \n",
    "            category_dir = self.output_path / category\n",
    "            category_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            print(f\"\\n   ğŸ“ {category.upper()}: {len(filepaths)} unique files\")\n",
    "            \n",
    "            copied_count = 0\n",
    "            for filepath in filepaths:\n",
    "                try:\n",
    "                    # Create unique filename to avoid conflicts\n",
    "                    # Format: original_directory__filename.tex\n",
    "                    source_dir = filepath.parent.name\n",
    "                    new_filename = f\"{source_dir}__{filepath.name}\"\n",
    "                    dest_path = category_dir / new_filename\n",
    "                    \n",
    "                    # Copy file\n",
    "                    shutil.copy2(filepath, dest_path)\n",
    "                    copied_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"      âš ï¸  Error copying {filepath.name}: {e}\")\n",
    "            \n",
    "            stats[category] = {\n",
    "                'total': len(filepaths),\n",
    "                'copied': copied_count\n",
    "            }\n",
    "            \n",
    "            print(f\"      âœ… Copied {copied_count}/{len(filepaths)} files\")\n",
    "        \n",
    "        # Create index/mapping file\n",
    "        print(f\"\\nğŸ“„ Creating mapping file...\")\n",
    "        self._create_mapping_file(resume_mappings)\n",
    "        \n",
    "        # Create summary report\n",
    "        self._create_summary_report(stats, resume_mappings)\n",
    "        \n",
    "        print(f\"\\nâœ… Organization complete!\")\n",
    "        print(f\"   Output directory: {self.output_path}\")\n",
    "        print(f\"   Total categories: {len(stats)}\")\n",
    "        print(f\"   Total unique files: {sum(s['copied'] for s in stats.values())}\")\n",
    "    \n",
    "    def _create_mapping_file(self, resume_mappings: List[Dict]):\n",
    "        \"\"\"Create a JSON mapping file showing which files belong to which resume.\"\"\"\n",
    "        import json\n",
    "        \n",
    "        mapping_file = self.output_path / \"file_mappings.json\"\n",
    "        \n",
    "        with open(mapping_file, 'w') as f:\n",
    "            json.dump(resume_mappings, f, indent=2)\n",
    "        \n",
    "        print(f\"      âœ… Saved: file_mappings.json\")\n",
    "    \n",
    "    def _create_summary_report(self, stats: Dict, resume_mappings: List[Dict]):\n",
    "        \"\"\"Create a summary report in markdown format.\"\"\"\n",
    "        \n",
    "        report_file = self.output_path / \"ORGANIZATION_REPORT.md\"\n",
    "        \n",
    "        with open(report_file, 'w') as f:\n",
    "            f.write(\"# CV Files Organization Report\\n\\n\")\n",
    "            f.write(f\"Generated: {pd.Timestamp.now()}\\n\\n\")\n",
    "            \n",
    "            f.write(\"## Summary\\n\\n\")\n",
    "            f.write(f\"- Total resumes processed: {len(resume_mappings)}\\n\")\n",
    "            f.write(f\"- Total categories: {len(stats)}\\n\")\n",
    "            f.write(f\"- Total unique files: {sum(s['copied'] for s in stats.values())}\\n\\n\")\n",
    "            \n",
    "            f.write(\"## Files by Category\\n\\n\")\n",
    "            for category, stat in sorted(stats.items()):\n",
    "                f.write(f\"### {category.replace('_', ' ').title()}\\n\")\n",
    "                f.write(f\"- Files: {stat['copied']}\\n\")\n",
    "                f.write(f\"- Location: `{category}/`\\n\\n\")\n",
    "            \n",
    "            f.write(\"## Directory Structure\\n\\n\")\n",
    "            f.write(\"```\\n\")\n",
    "            f.write(\"organized_files/\\n\")\n",
    "            for category in sorted(stats.keys()):\n",
    "                f.write(f\"â”œâ”€â”€ {category}/\\n\")\n",
    "                f.write(f\"â”‚   â””â”€â”€ (Contains {stats[category]['copied']} files)\\n\")\n",
    "            f.write(\"â”œâ”€â”€ file_mappings.json\\n\")\n",
    "            f.write(\"â””â”€â”€ ORGANIZATION_REPORT.md\\n\")\n",
    "            f.write(\"```\\n\\n\")\n",
    "            \n",
    "            f.write(\"## File Naming Convention\\n\\n\")\n",
    "            f.write(\"Files are named as: `{original_directory}__{original_filename}.tex`\\n\\n\")\n",
    "            f.write(\"This preserves the source directory information and prevents filename conflicts.\\n\\n\")\n",
    "            \n",
    "            f.write(\"## Usage\\n\\n\")\n",
    "            f.write(\"1. Browse files by category in their respective directories\\n\")\n",
    "            f.write(\"2. Use `file_mappings.json` to see which files belong to which resume\\n\")\n",
    "            f.write(\"3. Search for specific patterns across categories\\n\")\n",
    "            f.write(\"4. Use as reference for creating new CVs\\n\")\n",
    "        \n",
    "        print(f\"      âœ… Saved: ORGANIZATION_REPORT.md\")\n",
    "    \n",
    "    def create_category_index(self):\n",
    "        \"\"\"Create an index file for each category showing all files.\"\"\"\n",
    "        print(f\"\\nğŸ“‹ Creating category indexes...\")\n",
    "        \n",
    "        for category_dir in self.output_path.iterdir():\n",
    "            if not category_dir.is_dir():\n",
    "                continue\n",
    "            \n",
    "            category = category_dir.name\n",
    "            index_file = category_dir / \"INDEX.md\"\n",
    "            \n",
    "            # Get all files in this category\n",
    "            tex_files = sorted(category_dir.glob(\"*.tex\"))\n",
    "            \n",
    "            with open(index_file, 'w') as f:\n",
    "                f.write(f\"# {category.replace('_', ' ').title()} Files\\n\\n\")\n",
    "                f.write(f\"Total files: {len(tex_files)}\\n\\n\")\n",
    "                \n",
    "                f.write(\"## Files\\n\\n\")\n",
    "                for tex_file in tex_files:\n",
    "                    # Extract original directory name\n",
    "                    parts = tex_file.stem.split('__')\n",
    "                    original_dir = parts[0] if len(parts) > 1 else 'unknown'\n",
    "                    original_name = '__'.join(parts[1:]) if len(parts) > 1 else tex_file.stem\n",
    "                    \n",
    "                    f.write(f\"### {tex_file.name}\\n\")\n",
    "                    f.write(f\"- **Source Directory:** {original_dir}\\n\")\n",
    "                    f.write(f\"- **Original Name:** {original_name}.tex\\n\")\n",
    "                    f.write(f\"- **Size:** {tex_file.stat().st_size} bytes\\n\")\n",
    "                    \n",
    "                    # Try to read first few lines\n",
    "                    try:\n",
    "                        with open(tex_file, 'r', encoding='utf-8') as tf:\n",
    "                            lines = [line.strip() for line in tf.readlines()[:5] if line.strip() and not line.strip().startswith('%')]\n",
    "                            if lines:\n",
    "                                f.write(f\"- **Preview:**\\n```latex\\n{chr(10).join(lines[:3])}\\n...\\n```\\n\")\n",
    "                    except:\n",
    "                        pass\n",
    "                    \n",
    "                    f.write(\"\\n\")\n",
    "            \n",
    "            print(f\"   âœ… Created index for: {category}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# ANALYSIS TOOLS\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "class CVAnalysisTools:\n",
    "    \"\"\"Additional analysis tools for organized CV files.\"\"\"\n",
    "    \n",
    "    def __init__(self, organized_path: str):\n",
    "        self.organized_path = Path(organized_path)\n",
    "    \n",
    "    def find_similar_files(self, query: str, category: str = None) -> List[Path]:\n",
    "        \"\"\"Find files matching a query string.\"\"\"\n",
    "        print(f\"\\nğŸ” Searching for: '{query}'\")\n",
    "        \n",
    "        if category:\n",
    "            search_dirs = [self.organized_path / category]\n",
    "        else:\n",
    "            search_dirs = [d for d in self.organized_path.iterdir() if d.is_dir()]\n",
    "        \n",
    "        matching_files = []\n",
    "        \n",
    "        for search_dir in search_dirs:\n",
    "            if not search_dir.exists():\n",
    "                continue\n",
    "            \n",
    "            for tex_file in search_dir.glob(\"*.tex\"):\n",
    "                try:\n",
    "                    with open(tex_file, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                        content = f.read().lower()\n",
    "                        if query.lower() in content:\n",
    "                            matching_files.append(tex_file)\n",
    "                except:\n",
    "                    pass\n",
    "        \n",
    "        print(f\"âœ… Found {len(matching_files)} matching files\")\n",
    "        \n",
    "        return matching_files\n",
    "    \n",
    "    def compare_files(self, file1: Path, file2: Path):\n",
    "        \"\"\"Compare two CV files and show differences.\"\"\"\n",
    "        print(f\"\\nğŸ“Š Comparing:\")\n",
    "        print(f\"   File 1: {file1.name}\")\n",
    "        print(f\"   File 2: {file2.name}\")\n",
    "        \n",
    "        try:\n",
    "            with open(file1, 'r') as f:\n",
    "                content1 = set(f.readlines())\n",
    "            \n",
    "            with open(file2, 'r') as f:\n",
    "                content2 = set(f.readlines())\n",
    "            \n",
    "            unique_to_1 = content1 - content2\n",
    "            unique_to_2 = content2 - content1\n",
    "            common = content1 & content2\n",
    "            \n",
    "            print(f\"\\n   Common lines: {len(common)}\")\n",
    "            print(f\"   Unique to {file1.name}: {len(unique_to_1)}\")\n",
    "            print(f\"   Unique to {file2.name}: {len(unique_to_2)}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   âŒ Error: {e}\")\n",
    "    \n",
    "    def create_statistics_report(self):\n",
    "        \"\"\"Create detailed statistics about organized files.\"\"\"\n",
    "        print(f\"\\nğŸ“Š Generating statistics...\")\n",
    "        \n",
    "        stats = {}\n",
    "        \n",
    "        for category_dir in self.organized_path.iterdir():\n",
    "            if not category_dir.is_dir():\n",
    "                continue\n",
    "            \n",
    "            category = category_dir.name\n",
    "            tex_files = list(category_dir.glob(\"*.tex\"))\n",
    "            \n",
    "            # Calculate statistics\n",
    "            total_size = sum(f.stat().st_size for f in tex_files)\n",
    "            avg_size = total_size / len(tex_files) if tex_files else 0\n",
    "            \n",
    "            # Count unique source directories\n",
    "            source_dirs = set()\n",
    "            for tex_file in tex_files:\n",
    "                parts = tex_file.stem.split('__')\n",
    "                if len(parts) > 1:\n",
    "                    source_dirs.add(parts[0])\n",
    "            \n",
    "            stats[category] = {\n",
    "                'files': len(tex_files),\n",
    "                'total_size': total_size,\n",
    "                'avg_size': avg_size,\n",
    "                'source_dirs': len(source_dirs)\n",
    "            }\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(stats).T\n",
    "        df = df.sort_values('files', ascending=False)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*70)\n",
    "        print(\"ğŸ“ˆ STATISTICS SUMMARY\")\n",
    "        print(\"=\"*70)\n",
    "        print(df.to_string())\n",
    "        \n",
    "        # Save to CSV\n",
    "        stats_file = self.organized_path / \"statistics.csv\"\n",
    "        df.to_csv(stats_file)\n",
    "        print(f\"\\nâœ… Saved statistics to: {stats_file}\")\n",
    "\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "# MAIN EXECUTION\n",
    "# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main execution function.\"\"\"\n",
    "    \n",
    "    print(\"=\"*70)\n",
    "    print(\"ğŸ“ CV FILES ORGANIZER\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nğŸ“‚ Source: {AWESOME_CV_BASE}\")\n",
    "    print(f\"ğŸ“‚ Output: {OUTPUT_ORGANIZED}\")\n",
    "    \n",
    "    # Create organizer\n",
    "    organizer = CVFilesOrganizer(AWESOME_CV_BASE, OUTPUT_ORGANIZED)\n",
    "    \n",
    "    # Organize files\n",
    "    organizer.organize_files()\n",
    "    \n",
    "    # Create category indexes\n",
    "    organizer.create_category_index()\n",
    "    \n",
    "    # Run analysis\n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“Š RUNNING ANALYSIS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    analyzer = CVAnalysisTools(OUTPUT_ORGANIZED)\n",
    "    analyzer.create_statistics_report()\n",
    "    \n",
    "    # Example searches\n",
    "    print(f\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ” EXAMPLE SEARCHES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Search for bioinformatics-related summaries\n",
    "    bio_files = analyzer.find_similar_files(\"bioinformatics\", category=\"summary\")\n",
    "    if bio_files:\n",
    "        print(f\"\\n   Top bioinformatics summaries:\")\n",
    "        for f in bio_files[:3]:\n",
    "            print(f\"      â€¢ {f.name}\")\n",
    "    \n",
    "    # Search for Python skills\n",
    "    python_files = analyzer.find_similar_files(\"python\", category=\"key_skills\")\n",
    "    if python_files:\n",
    "        print(f\"\\n   Files mentioning Python:\")\n",
    "        for f in python_files[:3]:\n",
    "            print(f\"      â€¢ {f.name}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… ORGANIZATION COMPLETE!\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\nğŸ“ Check output directory: {OUTPUT_ORGANIZED}\")\n",
    "    print(f\"ğŸ“„ Read: ORGANIZATION_REPORT.md\")\n",
    "    print(f\"ğŸ“‹ Browse categories:\")\n",
    "    \n",
    "    for category_dir in Path(OUTPUT_ORGANIZED).iterdir():\n",
    "        if category_dir.is_dir():\n",
    "            file_count = len(list(category_dir.glob(\"*.tex\")))\n",
    "            print(f\"      â€¢ {category_dir.name}/  ({file_count} files)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a86c7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Copied: file_mappings.json\n",
      "âœ… Copied: ORGANIZATION_REPORT.md\n",
      "âœ… Copied: statistics.csv\n",
      "âœ… Copied: experience/business_Data_Prec_Med_2025_10__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_08__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/DS_engineer_2024_03__experience_DS_it_2025_03.tex\n",
      "âœ… Copied: experience/Bioinformatics_Data_product_2025_04__experience_data_product_2025_04.tex\n",
      "âœ… Copied: experience/DS_Healthcare_2025_05__experience_DS_2025_05.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_07_biot__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/Data_Science_Novartis_2025_08__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/LEAD_data_engineer_JJ_2025_10__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/IT_HPC_Pfizer_2025_04__experience_IT_2025_04.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_09_biomarkers__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/Plants_2025_03__experience_bioinformatics_2025_03.tex\n",
      "âœ… Copied: experience/Senior_Bioinformatics_Scientist_Roche_2025_11__experience.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_10_RNA__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_03__experience_bioinformatics_2025_03.tex\n",
      "âœ… Copied: experience/IT_HPC_2025_04__experience_IT_2025_04.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_05__experience_bioinformatics_2025_05.tex\n",
      "âœ… Copied: experience/Bioinformatics_2024_10__experience_Bioinformatics_Business_2024_10.tex\n",
      "âœ… Copied: experience/Data_Architect_2025_07__experience_data_arch_2.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_09__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/DS_Healthcare_2025_05_epi__experience_DS_2025_05.tex\n",
      "âœ… Copied: experience/Software_dev_2025_09__experience_soft_2025_09.tex\n",
      "âœ… Copied: experience/Plants_2025_09__experience_bioinformatics_2025_03.tex\n",
      "âœ… Copied: experience/Bioinformatics_manager_2024_12__experience_Bioinformatics_Business_2024_10B.tex\n",
      "âœ… Copied: experience/business_Data_Med_2025_09__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_07_biomarkers__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/client_Platform_Nvidia_Med_2025_10__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/client_Platform_Med_2025_10__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/IT_Manager_2025_04__experience_Business_IT_2025_04.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_06__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/Data_Science_Takeda_2025_06__experience_data_arch_2025_05.tex\n",
      "âœ… Copied: experience/INDEX.md\n",
      "âœ… Copied: experience/Data_Architect_2025_05__experience_data_arch_2025_05.tex\n",
      "âœ… Copied: experience/Bioinformatics_2024_09__experience_Bioinformatics_Business_2024_09.tex\n",
      "âœ… Copied: experience/DS_clinical_2024_09__experience_DS_cli_bio_2024_09.tex\n",
      "âœ… Copied: experience/IT_HPC_Pfizer_2025_04__experience_IT_Bio_2025_04.tex\n",
      "âœ… Copied: experience/Bioinformatics_2024_09__experience_bioinfo_2024_09.tex\n",
      "âœ… Copied: experience/DS_Healthcare_2025_04__experience_Bioinformatics_Business_2024_10B.tex\n",
      "âœ… Copied: experience/DS_Healthcare_2025_09_patient_data__experience_DS_Business_patient_data.tex\n",
      "âœ… Copied: experience/Data_Product_2025_06__experience_data_arch.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_04_ncRNA__experience_bioinformatics_2025_03.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_09_cancer__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/Bioinformatics_2024_07__experience_bioinfo_AI_2024_07.tex\n",
      "âœ… Copied: experience/Data_Architect_2025_06__experience_data_arch.tex\n",
      "âœ… Copied: experience/DS_LIMS_2025_06__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/Data_Analytics_Med_2025_08__experience_bioinformatics.tex\n",
      "âœ… Copied: experience/Plants_2025_07__experience_bioinformatics_2025_03.tex\n",
      "âœ… Copied: experience/DS_2025__experience_DS_it_2025_03.tex\n",
      "âœ… Copied: experience/Bioinformatics_2024_07__experience_bioinfo_business_2024_07.tex\n",
      "âœ… Copied: experience/Bioinformatics_2025_10_SIB__experience_bioinformatics.tex\n",
      "âœ… Copied: education/Data_Science_Novartis_2025_08__education.tex\n",
      "âœ… Copied: education/Plants_2025_07__education.tex\n",
      "ğŸ” Duplicate skipped: business_Data_Med_2025_09__education.tex\n",
      "âœ… Copied: education/Plants_2025_09__education.tex\n",
      "âœ… Copied: education/LEAD_data_engineer_JJ_2025_10__education.tex\n",
      "ğŸ” Duplicate skipped: Data_Analytics_Med_2025_08__education.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_07_biomarkers__education.tex\n",
      "âœ… Copied: education/Bioinformatics_2025_10_RNA__education.tex\n",
      "âœ… Copied: education/Bioinformatics_2025_09_cancer__education.tex\n",
      "ğŸ” Duplicate skipped: client_Platform_Med_2025_10__education.tex\n",
      "âœ… Copied: education/Bioinformatics_2025_10_SIB__education.tex\n",
      "âœ… Copied: education/INDEX.md\n",
      "ğŸ” Duplicate skipped: business_Data_Prec_Med_2025_10__education.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_09__education.tex\n",
      "âœ… Copied: education/Software_dev_2025_09__education_2024_08.tex\n",
      "ğŸ” Duplicate skipped: client_Platform_Nvidia_Med_2025_10__education.tex\n",
      "ğŸ” Duplicate skipped: DS_Healthcare_2025_09_patient_data__education_2024_08.tex\n",
      "âœ… Copied: education/Bioinformatics_2025_09_biomarkers__education.tex\n",
      "âœ… Copied: additional_info/Bioinformatics_2025_10_SIB__additional_info.tex\n",
      "âœ… Copied: additional_info/Data_Analytics_Med_2025_08__additional_info.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_07_biomarkers__additional_info.tex\n",
      "ğŸ” Duplicate skipped: business_Data_Med_2025_09__additional_info.tex\n",
      "âœ… Copied: additional_info/LEAD_data_engineer_JJ_2025_10__additional_info.tex\n",
      "ğŸ” Duplicate skipped: client_Platform_Nvidia_Med_2025_10__additional_info.tex\n",
      "âœ… Copied: additional_info/Bioinformatics_2025_09_biomarkers__additional_info.tex\n",
      "âœ… Copied: additional_info/Bioinformatics_2025_10_RNA__additional_info.tex\n",
      "ğŸ” Duplicate skipped: client_Platform_Med_2025_10__additional_info.tex\n",
      "ğŸ” Duplicate skipped: business_Data_Prec_Med_2025_10__additional_info.tex\n",
      "âœ… Copied: additional_info/INDEX.md\n",
      "ğŸ” Duplicate skipped: Data_Science_Novartis_2025_08__additional_info.tex\n",
      "âœ… Copied: additional_info/Bioinformatics_2025_09__additional_info.tex\n",
      "âœ… Copied: additional_info/Bioinformatics_2025_09_cancer__additional_info.tex\n",
      "âœ… Copied: key_skills/Data_Architect_2025_06__additional_info_noSkills.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_manager_2024_12__additional_info_noSkills_2024_12.tex\n",
      "ğŸ” Duplicate skipped: DS_Healthcare_2025_09_patient_data__additional_info_noSkills_2025_04.tex\n",
      "âœ… Copied: key_skills/LEAD_data_engineer_JJ_2025_10__key_skills.tex\n",
      "âœ… Copied: key_skills/IT_Manager_2025_04__key_skills_2025_04_DS_compressed.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_Data_product_2025_04__key_skills_2025_04_bio_business.tex\n",
      "âœ… Copied: key_skills/DS_LIMS_2025_06__key_skills.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2024_10__key_skills_2024_10_DS.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_04_ncRNA__key_skills_2025_03.tex\n",
      "âœ… Copied: key_skills/DS_clinical_2024_09__key_skills_2024_09_DS.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_08__key_skills.tex\n",
      "âœ… Copied: key_skills/DS_Healthcare_2025_09_patient_data__key_skills_2025_05_bio_business.tex\n",
      "âœ… Copied: key_skills/business_Data_Prec_Med_2025_10__key_skills.tex\n",
      "âœ… Copied: key_skills/IT_Manager_2025_04__additional_info_noSkills_2025_04.tex\n",
      "âœ… Copied: key_skills/Plants_2025_09__additional_info_noSkills_2025_03.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_05__key_skills_2025_05_R.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2024_07__key_skills_2024_05_bioinformatics.tex\n",
      "âœ… Copied: key_skills/DS_LIMS_2025_06__additional_info_noSkills.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_09_cancer__key_skills.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_10_SIB__key_skills.tex\n",
      "âœ… Copied: key_skills/Data_Product_2025_06__key_skills.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_09_biomarkers__key_skills.tex\n",
      "âœ… Copied: key_skills/Plants_2025_07__key_skills_2025_03.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_04_ncRNA__additional_info_noSkills_2025_03.tex\n",
      "âœ… Copied: key_skills/Software_dev_2025_09__key_skills_2025_05.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2024_09__key_skills_2024_09_bioinformatics.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_10_RNA__key_skills.tex\n",
      "ğŸ” Duplicate skipped: Data_Architect_2025_07__additional_info_noSkills.tex\n",
      "âœ… Copied: key_skills/Data_Analytics_Med_2025_08__key_skills.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_06__key_skills.tex\n",
      "âœ… Copied: key_skills/Plants_2025_03__key_skills_2025_03.tex\n",
      "âœ… Copied: key_skills/DS_Healthcare_2025_05_epi__key_skills_2025_05_bio_business.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2024_09__key_skills_2024_09_DS.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_05__key_skills_2025_05.tex\n",
      "âœ… Copied: key_skills/Data_Science_Novartis_2025_08__key_skills.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_09__key_skills.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_07_biomarkers__key_skills.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_07_biot__key_skills.tex\n",
      "âœ… Copied: key_skills/Data_Architect_2025_05__key_skills_2025_05.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_2025_03__additional_info_noSkills_2025_03.tex\n",
      "âœ… Copied: key_skills/INDEX.md\n",
      "âœ… Copied: key_skills/Plants_2025_07__additional_info_noSkills_2025_03.tex\n",
      "âœ… Copied: key_skills/client_Platform_Nvidia_Med_2025_10__key_skills.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_05__additional_info_noSkills_2025_04.tex\n",
      "âœ… Copied: key_skills/IT_HPC_2025_04__key_skills_2025_04_IT.tex\n",
      "âœ… Copied: key_skills/Data_Architect_2025_07__key_skills.tex\n",
      "âœ… Copied: key_skills/DS_engineer_2024_03__key_skills_2025_03.tex\n",
      "âœ… Copied: key_skills/DS_Healthcare_2025_05__key_skills_2025_05_bio_business.tex\n",
      "âœ… Copied: key_skills/Bioinformatics_Manager_2024_12__key_skills_2024_10_DSB.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_03__key_skills_2025_03.tex\n",
      "âœ… Copied: key_skills/Plants_2025_03__additional_info_noSkills_2025_03.tex\n",
      "ğŸ” Duplicate skipped: business_Data_Med_2025_09__key_skills.tex\n",
      "âœ… Copied: key_skills/IT_HPC_Pfizer_2025_04__key_skills_2025_04_IT.tex\n",
      "ğŸ” Duplicate skipped: Data_Product_2025_06__additional_info_noSkills.tex\n",
      "âœ… Copied: key_skills/Data_Architect_2025_06__key_skills.tex\n",
      "ğŸ” Duplicate skipped: Data_Science_Takeda_2025_06__key_skills_2025_05.tex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Copied: key_skills/client_Platform_Med_2025_10__key_skills.tex\n",
      "âœ… Copied: key_skills/Plants_2025_09__key_skills_2025_03.tex\n",
      "âœ… Copied: summary/Bioinformatics_2025_09_cancer__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/business_Data_Med_2025_09__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/Bioinformatics_2025_03__summary_bioinformatics_busi_2025_03.tex\n",
      "âœ… Copied: summary/DS_Healthcare_2025_09_patient_data__summary_bioinformatics_DS_business_2025_03.tex\n",
      "âœ… Copied: summary/business_Data_Prec_Med_2025_10__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/DS_2025__summary_DS_project_busi_2025_03.tex\n",
      "âœ… Copied: summary/Data_Science_Novartis_2025_08__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/Data_Architect_2025_07__summary_data_busi.tex\n",
      "âœ… Copied: summary/Bioinformatics_2024_09__summary_bioinformatics_busi_2024_09.tex\n",
      "âœ… Copied: summary/Bioinformatics_2024_09__summary_bioinformatics_2024_09.tex\n",
      "âœ… Copied: summary/Bioinformatics_2025_07_biot__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/Data_Science_Takeda_2025_06__summary_data_busi_2025_05.tex\n",
      "âœ… Copied: summary/Lead_2024_10__summary_bioinformatics_busi_2024_10.tex\n",
      "âœ… Copied: summary/DS_Healthcare_2025_04__summary_bioinformatics_DS_business_2025_03.tex\n",
      "âœ… Copied: summary/Data_Architect_2025_05__summary_data_busi_2025_05_R.tex\n",
      "âœ… Copied: summary/Bioinformatics_2025_10_RNA__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/Data_Architect_2025_06__summary_data_busi.tex\n",
      "âœ… Copied: summary/client_Platform_Nvidia_Med_2025_10__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/client_Platform_Med_2025_10__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/Bioinformatics_2025_10_SIB__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/Bioinformatics_2024_10__summary_bioinformatics_busi_2024_10.tex\n",
      "âœ… Copied: summary/IT_HPC_2025_04__summary_2025_04.tex\n",
      "ğŸ” Duplicate skipped: IT_HPC_Pfizer_2025_04__summary_2025_04.tex\n",
      "ğŸ” Duplicate skipped: DS_Healthcare_2025_05__summary_bioinformatics_DS_business_2025_03.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_09_biomarkers__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/DS_clinical_2024_09__summary_DS_clinical_2024_09.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_09__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/Plants_2025_09__summary_plants_2025_03.tex\n",
      "âœ… Copied: summary/INDEX.md\n",
      "âœ… Copied: summary/Plants_2025_03__summary_plants_2025_03.tex\n",
      "âœ… Copied: summary/Senior_Bioinformatics_Scientist_Roche_2025_11__summary.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_04_ncRNA__summary_bioinformatics_busi_2025_03.tex\n",
      "âœ… Copied: summary/Data_Product_2025_06__summary_data_busi.tex\n",
      "âœ… Copied: summary/Bioinformatics_2025_06__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/Data_Analytics_Med_2025_08__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/IT_Manager_2025_04__summary_business_2025_04.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_manager_2024_12__summary_bioinformatics_busi_2024_10.tex\n",
      "âœ… Copied: summary/Bioinformatics_2025_08__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/LEAD_data_engineer_JJ_2025_10__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/DS_LIMS_2025_06__summary_bioinformatics.tex\n",
      "âœ… Copied: summary/Bioinformatics_2025_05__summary_bioinformatics_busi_2025_05.tex\n",
      "âœ… Copied: summary/Software_dev_2025_09__summary_data_busi_2025_05.tex\n",
      "âœ… Copied: summary/DS_Healthcare_2025_05_epi__summary_bioinformatics_DS_business_2025_03.tex\n",
      "âœ… Copied: summary/Plants_2025_07__summary_plants_2025_03.tex\n",
      "âœ… Copied: summary/Data_Architect_2025_05__summary_data_busi_2025_05.tex\n",
      "âœ… Copied: summary/DS_engineer_2024_03__summary_business_2024_09.tex\n",
      "ğŸ” Duplicate skipped: Bioinformatics_2025_07_biomarkers__summary_bioinformatics.tex\n",
      "\n",
      "âœ… Finished. 158 unique files copied to /Users/kbillis/bin/Awesome-CV/organized_filesdeduplicated/\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import shutil\n",
    "from collections import defaultdict\n",
    "\n",
    "def hash_file(filepath, chunk_size=8192):\n",
    "    \"\"\"Generate SHA256 hash for a file.\"\"\"\n",
    "    hasher = hashlib.sha256()\n",
    "    with open(filepath, 'rb') as f:\n",
    "        while chunk := f.read(chunk_size):\n",
    "            hasher.update(chunk)\n",
    "    return hasher.hexdigest()\n",
    "\n",
    "def copy_unique_files(src_dir, dest_dir):\n",
    "    \"\"\"Copy only unique files from src_dir to dest_dir.\"\"\"\n",
    "    os.makedirs(dest_dir, exist_ok=True)\n",
    "    seen_hashes = set()\n",
    "    hash_to_path = {}\n",
    "\n",
    "    for dirpath, _, filenames in os.walk(src_dir):\n",
    "        for filename in filenames:\n",
    "            full_path = os.path.join(dirpath, filename)\n",
    "            try:\n",
    "                file_hash = hash_file(full_path)\n",
    "                if file_hash not in seen_hashes:\n",
    "                    seen_hashes.add(file_hash)\n",
    "                    hash_to_path[file_hash] = full_path\n",
    "\n",
    "                    # Preserve relative path structure\n",
    "                    rel_path = os.path.relpath(full_path, src_dir)\n",
    "                    dest_path = os.path.join(dest_dir, rel_path)\n",
    "                    os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n",
    "                    shutil.copy2(full_path, dest_path)\n",
    "                    print(f\"âœ… Copied: {rel_path}\")\n",
    "                else:\n",
    "                    print(f\"ğŸ” Duplicate skipped: {filename}\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸ Error processing {full_path}: {e}\")\n",
    "\n",
    "    return hash_to_path\n",
    "\n",
    "# ğŸ” Run the deduplication\n",
    "source_directory = OUTPUT_ORGANIZED\n",
    "output_directory = OUTPUT_ORGANIZED+\"deduplicated/\"\n",
    "unique_files = copy_unique_files(source_directory, output_directory)\n",
    "\n",
    "print(f\"\\nâœ… Finished. {len(unique_files)} unique files copied to {output_directory}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "everyday_repo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
